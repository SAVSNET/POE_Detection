{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a95efa-2e2e-409e-982d-720ae3a38b5a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2421eb-ae60-4c51-813c-00417e09c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from datasets import load_dataset, load_metric\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import accelerate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7e164-3159-4071-9e78-5fb8442f14c9",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea235ffa-d699-4bcb-bba1-fe3d7a2275b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/jupyterlab/notebooks/DogBERT/Classifiers/Pseudomonas_Otitis/Binary_Classifier/Binary_Weighted_Loss\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713e4799-3537-4fb1-909d-46b6e7b0f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psoe = pd.read_excel('adamwilliams-OtitisStudyPseudomonas (1).xls', sheet_name='Case Data', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c7ced60-17b4-446e-b3a6-22d6b5d867b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0            searchterm__name  savsnet_consult_id  \\\n",
      "0           0  Pseudomonas and ear/otitis               95721   \n",
      "1           1  Pseudomonas and ear/otitis              129032   \n",
      "2           2  Pseudomonas and ear/otitis              169684   \n",
      "3           3  Pseudomonas and ear/otitis              117477   \n",
      "4           4  Pseudomonas and ear/otitis              115552   \n",
      "\n",
      "   narrative_item_id PseudomonasOtitis PseudomonasOtitis related_text species  \n",
      "0            2040703                 ?                            NaN     dog  \n",
      "1            2041630                 ✓                            NaN     dog  \n",
      "2            2042546                 ✓                            NaN     dog  \n",
      "3            2044364                 ✓                            NaN     dog  \n",
      "4            2049428                 !                            NaN     dog  \n"
     ]
    }
   ],
   "source": [
    "print(df_psoe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996d60e0-ebf2-4777-9a79-f5196683d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../../../../savsnet_resources/pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae3f2953-93ed-45b7-a807-ecd699c0a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_narratives = pd.read_pickle('narrative_pickle.pkl.gz', compression='gzip').drop_duplicates(subset='savsnet_consult_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449e5ea6-e164-47f4-9198-c8da46d22383",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../DogBERT/Classifiers/Pseudomonas_Otitis/Binary_Classifier/Binary_Weighted_Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac94f8ec-d72a-4f11-93a3-4fcc937eec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for just dog records\n",
    "df_psoe = df_psoe[df_psoe.species == 'dog']\n",
    "\n",
    "# Remove unclassified records\n",
    "df_psoe = df_psoe.dropna(subset=['PseudomonasOtitis'])\n",
    "\n",
    "\"\"\"\n",
    "Create Dataset\n",
    "\"\"\"\n",
    "# Join in tick labels\n",
    "df_dataset = pd.merge(df_narratives, df_psoe, on='savsnet_consult_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3849f03e-1c35-4ef0-9323-0ebc21833df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           item_text  consult_record       pk  \\\n",
      "0  \"<<identifier>> otitis externa been really goo...          231003  2040703   \n",
      "1  \"HL issues and ears. been slowing up last few ...          231674  2041630   \n",
      "2  \"bilateral oe thickened ear canals cleaning is...          232326  2042546   \n",
      "3  \"left eear purulent otitis suspecrt pseudomona...          233568  2044364   \n",
      "4  \"Bilat OE again. Not purulent or ulcerated, so...          237069  2049428   \n",
      "\n",
      "        consult_record_date  savsnet_consult_id  Unnamed: 0  \\\n",
      "0 2014-06-30 17:09:38+00:00               95721           0   \n",
      "1 2014-07-26 11:24:00+00:00              129032           1   \n",
      "2 2014-08-29 16:22:44+00:00              169684           2   \n",
      "3 2014-07-16 19:29:10+00:00              117477           3   \n",
      "4 2014-07-15 17:17:57+00:00              115552           4   \n",
      "\n",
      "             searchterm__name  narrative_item_id PseudomonasOtitis  \\\n",
      "0  Pseudomonas and ear/otitis            2040703                 ?   \n",
      "1  Pseudomonas and ear/otitis            2041630                 ✓   \n",
      "2  Pseudomonas and ear/otitis            2042546                 ✓   \n",
      "3  Pseudomonas and ear/otitis            2044364                 ✓   \n",
      "4  Pseudomonas and ear/otitis            2049428                 !   \n",
      "\n",
      "  PseudomonasOtitis related_text species  \n",
      "0                            NaN     dog  \n",
      "1                            NaN     dog  \n",
      "2                            NaN     dog  \n",
      "3                            NaN     dog  \n",
      "4                            NaN     dog  \n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3925ec6-3cd7-4672-8f22-e32630e84965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labels to make it a binary classifier\n",
    "replacements = {'⍉':'x', '?':'x', '!':'x'}\n",
    "df_dataset['PseudomonasOtitis'] = df_dataset['PseudomonasOtitis'].replace(replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1464946a-8ee2-4b98-b19b-36218bb834ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ids that can be fed into the model\n",
    "def tick_label_ids(symbol):\n",
    "    if symbol == '✓':\n",
    "        return 0\n",
    "    elif symbol == 'x':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf049fb-d9a1-4ce5-a4c1-e0cc602bf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label dataset   \n",
    "df_dataset['PseudomonasOtitis_ID'] = df_dataset['PseudomonasOtitis'].apply(tick_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "126cd91d-21c8-4cf3-8fb7-ea6db7e97822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           item_text  consult_record       pk  \\\n",
      "0  \"<<identifier>> otitis externa been really goo...          231003  2040703   \n",
      "1  \"HL issues and ears. been slowing up last few ...          231674  2041630   \n",
      "2  \"bilateral oe thickened ear canals cleaning is...          232326  2042546   \n",
      "3  \"left eear purulent otitis suspecrt pseudomona...          233568  2044364   \n",
      "4  \"Bilat OE again. Not purulent or ulcerated, so...          237069  2049428   \n",
      "\n",
      "        consult_record_date  savsnet_consult_id  Unnamed: 0  \\\n",
      "0 2014-06-30 17:09:38+00:00               95721           0   \n",
      "1 2014-07-26 11:24:00+00:00              129032           1   \n",
      "2 2014-08-29 16:22:44+00:00              169684           2   \n",
      "3 2014-07-16 19:29:10+00:00              117477           3   \n",
      "4 2014-07-15 17:17:57+00:00              115552           4   \n",
      "\n",
      "             searchterm__name  narrative_item_id PseudomonasOtitis  \\\n",
      "0  Pseudomonas and ear/otitis            2040703                 x   \n",
      "1  Pseudomonas and ear/otitis            2041630                 ✓   \n",
      "2  Pseudomonas and ear/otitis            2042546                 ✓   \n",
      "3  Pseudomonas and ear/otitis            2044364                 ✓   \n",
      "4  Pseudomonas and ear/otitis            2049428                 x   \n",
      "\n",
      "  PseudomonasOtitis related_text species  PseudomonasOtitis_ID  \n",
      "0                            NaN     dog                     1  \n",
      "1                            NaN     dog                     0  \n",
      "2                            NaN     dog                     0  \n",
      "3                            NaN     dog                     0  \n",
      "4                            NaN     dog                     1  \n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09b1edbc-7788-4fb5-a99f-f64e2cf38b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PseudomonasOtitis\n",
      "✓    638\n",
      "x    256\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_dataset['PseudomonasOtitis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7950afff-9592-4b92-9383-6506a273ab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   savsnet_consult_id  label  \\\n",
      "0               95721      1   \n",
      "1              129032      0   \n",
      "2              169684      0   \n",
      "3              117477      0   \n",
      "4              115552      1   \n",
      "\n",
      "                                                text  \n",
      "0  \"<<identifier>> otitis externa been really goo...  \n",
      "1  \"HL issues and ears. been slowing up last few ...  \n",
      "2  \"bilateral oe thickened ear canals cleaning is...  \n",
      "3  \"left eear purulent otitis suspecrt pseudomona...  \n",
      "4  \"Bilat OE again. Not purulent or ulcerated, so...  \n"
     ]
    }
   ],
   "source": [
    "# Select get text and labels\n",
    "df_dataset = df_dataset[['savsnet_consult_id', 'PseudomonasOtitis_ID', 'item_text']]\n",
    "# Rename columns\n",
    "df_dataset = df_dataset.rename(columns={'PseudomonasOtitis_ID':'label', 'item_text':'text'})\n",
    "df_dataset.reset_index(drop=True)\n",
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b495fb-d3c0-4529-910b-a8ecdc581677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train/val/test split \n",
    "\"\"\"\n",
    "Split Each Category into 80/10/10 train/val/test sets\n",
    "\"\"\"\n",
    "# for each label in the dataframe, randomly select the number of records in the group_size. Note each index selected and remove from test set\n",
    "import random\n",
    "\n",
    "# get labels\n",
    "labels = df_dataset['label'].unique()\n",
    "\n",
    "# Set up train_set, val_set and test_set\n",
    "train_set = []\n",
    "val_set = []\n",
    "test_set = []\n",
    "\n",
    "#iterate over labels\n",
    "for label in labels:\n",
    "    # Get indexes of labels in a given group\n",
    "    indexes = df_dataset[df_dataset['label'] == label].index.to_list()\n",
    "    \n",
    "    # Get size of group\n",
    "    train_size = round(len(indexes) * 0.8)\n",
    "    val_test_size = round(len(indexes) * 0.1)\n",
    "    \n",
    "    # Randomly sample train_size indexes to make train_set. Remove these indexes \n",
    "    train_indexes = random.sample(indexes, train_size)\n",
    "    train_set += train_indexes\n",
    "    \n",
    "    # Remove train_indexes from overall indexes\n",
    "    indexes = list(set(indexes) - set(train_indexes))\n",
    "    \n",
    "    # Randomly sample val_test_size indexes to make val_set. Remove these indexes\n",
    "    val_indexes = random.sample(indexes, val_test_size)\n",
    "    val_set += val_indexes\n",
    "    \n",
    "    # Remove train_indexes from overall indexes\n",
    "    indexes = list(set(indexes) - set(val_indexes))\n",
    "    test_set += indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcae4112-90f8-4eec-b32c-5b3ea499283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val and test dataframes\n",
    "df_train = df_dataset.iloc[train_set].reset_index(drop=True)\n",
    "df_val = df_dataset.iloc[val_set].reset_index(drop=True)\n",
    "df_test = df_dataset.iloc[test_set].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aacf01c6-3816-4148-897c-fe105243a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/jupyterlab/notebooks/DogBERT/Classifiers/Pseudomonas_Otitis/Binary_Classifier/Binary_Weighted_Loss\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da0e223a-1665-41a3-92f0-274abbe680f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['label', 'text']]\n",
    "df_val = df_val[['label', 'text']]\n",
    "df_test = df_test[['label', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e57f56b-7fa4-451b-8750-64db2d47745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv')\n",
    "df_val.to_csv('val.csv')\n",
    "df_test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67196f15-30ec-4df8-971b-f8bb3ba8d418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5840a77ce66146728846bd92bb6e3ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224df711f9284700a124ae28dd41c550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76de4088d93243e488b306a2f0e367b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"csv\", data_files={'train': \"train.csv\",\n",
    "                                           'eval': \"val.csv\",\n",
    "                                           'test':\"test.csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50cd58-70ca-4767-b35d-d05603c5ab1f",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd08f230-ca9a-4994-9a9e-7b7cc104044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6b57a84-4d42-474c-a05d-a05914ca4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f2149ff-5fab-4f14-bc33-167d39b07985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1da8fa5c9f04ef9bde1b35072ca8357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022b35f3b93b4b65907274636be9061b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4266cf7605b4e089d6de9eecbb81dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_and_encode, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ddbd35-2fba-400b-a405-2b8123bf50d7",
   "metadata": {},
   "source": [
    "## Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bcc65c0-807d-4c61-b91f-93ba57d08289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label to Id and Id to labels\n",
    "id2label = {0: \"✓\", 1: \"x\"}\n",
    "label2id = {\"✓\": 0, \"x\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cf86f0f-b632-4b01-9d36-937de98a828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a685e43c-c22f-4748-8736-42a7d8d851ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup weights and biases stuff\n",
    "os.environ[\"WANDB_PROJECT\"]=\"Pseudomonas_Otitis_Classifier_Binary_Post_Regex\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76045be4-97a1-458f-bf8e-32a099b4fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"BERT_PSOE_Binary_Classifier_Filtered_Unweighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"BERT_Unweighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "733fdd8d-1467-4498-bf41-9d237786ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e66fae08-d242-4e27-8872-d8efc680aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39d81c62-4fbc-43fc-9de8-d590d8e79f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    metrics = {\"accuracy\": accuracy.compute(predictions=predictions, references=labels), \"f1\":f1.compute(predictions=predictions, references=labels)}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86139acb-0bdd-4bfe-bcb4-11bb92130feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9850/2812224309.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/900 01:16 < 06:25, 1.95 it/s, Epoch 5/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.599267</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.589191</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.675549</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.785293</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.984635</td>\n",
       "      <td>{'accuracy': 0.7333333333333333}</td>\n",
       "      <td>{'f1': 0.25}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-30)... Done. 2.3s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-60)... Done. 2.3s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-90)... Done. 2.2s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-120)... Done. 2.9s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-150)... Done. 1.9s\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "     model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47f7cb12-b251-49b9-9db1-d21864b764a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b722e9-dcb9-4e95-a20b-a09ec8d829f7",
   "metadata": {},
   "source": [
    "## BERT Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2401df98-7e60-40c5-82cb-9c404a713403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f1fb525-c0ea-487f-b61e-a87b9270fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.7439])\n",
      "{0: '✓', 1: 'x'}\n"
     ]
    }
   ],
   "source": [
    "# iterate over each column and calculate the weight based on max value in column\n",
    "#def calculate_class_weights(train_dataset, label_cols):\n",
    "labels = list(label2id.values())\n",
    "total_samples = len(df_train)\n",
    "label_lst = []\n",
    "class_weights = []\n",
    "for label in labels:\n",
    "    class_frequency = df_train['label'].value_counts()[label]\n",
    "    weight = total_samples / (2 * class_frequency)\n",
    "    if weight < 1:\n",
    "        weight = 1\n",
    "    class_weights.append(weight)\n",
    "    label_lst.append(label)\n",
    "        \n",
    "weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "print(weights)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb3ab48e-8394-4a9d-adc8-256f0813f6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"BERT_PSOE_Binary_Classifier_Filtered_Weighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"BERT_Weighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6a63ce3-12ba-4e12-918e-789cd2645428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(\n",
    "            weight=weights\n",
    "        ).to(\"cuda\")\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0878c6b-5768-467c-93f0-c97b0e93c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9850/28312920.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/900 01:13 < 06:13, 2.01 it/s, Epoch 5/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.631818</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.627796</td>\n",
       "      <td>{'accuracy': 0.6888888888888889}</td>\n",
       "      <td>{'f1': 0.06666666666666667}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.668799</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.748914</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.13333333333333333}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.842267</td>\n",
       "      <td>{'accuracy': 0.7444444444444445}</td>\n",
       "      <td>{'f1': 0.41025641025641024}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-30)... Done. 2.3s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-60)... Done. 2.4s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-90)... Done. 2.0s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-120)... Done. 2.3s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-150)... Done. 2.4s\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16eb1a2f-5cbe-4c07-8e51-2a392a6ba7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1427"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012c1bd-1203-4d9d-9c5c-294353f08bf9",
   "metadata": {},
   "source": [
    "## DogBERT Unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "795239ea-26a9-4ccb-959a-b28bbd0f04f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_dir = \"/opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78b7ac18-dc5f-4db8-ba28-10776f52fd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"DogBERT_Unweighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3309482-6dee-4efd-a43e-5f6e4c6ea3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9850/2812224309.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='161' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [161/230 01:38 < 00:42, 1.62 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.573224</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540590</td>\n",
       "      <td>{'accuracy': 0.7}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.492523</td>\n",
       "      <td>{'accuracy': 0.7888888888888889}</td>\n",
       "      <td>{'f1': 0.5128205128205128}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.479793</td>\n",
       "      <td>{'accuracy': 0.7777777777777778}</td>\n",
       "      <td>{'f1': 0.5652173913043478}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.858597</td>\n",
       "      <td>{'accuracy': 0.7666666666666667}</td>\n",
       "      <td>{'f1': 0.43243243243243246}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.832256</td>\n",
       "      <td>{'accuracy': 0.7777777777777778}</td>\n",
       "      <td>{'f1': 0.5238095238095238}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.908021</td>\n",
       "      <td>{'accuracy': 0.7666666666666667}</td>\n",
       "      <td>{'f1': 0.5531914893617021}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-23)... Done. 2.0s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-46)... Done. 2.3s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-69)... Done. 2.3s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-92)... Done. 2.3s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-115)... Done. 2.1s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-138)... Done. 2.1s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted/checkpoint-161)... Done. 2.1s\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "     model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf0476f0-f22d-4ce2-bd1b-ead7f3689874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed30f8-e3d6-470c-bf6b-44d7311a502e",
   "metadata": {},
   "source": [
    "## DogBERT Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34b6037b-bb80-4773-ac64-11c20e03a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_dir = \"/opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f8cef96-c536-4585-9ff8-d697ef706a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"DogBERT_PSOE_Binary_Classifier_Filtered_Weighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"DogBERT_Weighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ede127ae-3ad3-4341-9596-fee27be7d89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9850/28312920.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/690 01:25 < 05:46, 1.59 it/s, Epoch 6/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.616304</td>\n",
       "      <td>{'accuracy': 0.6555555555555556}</td>\n",
       "      <td>{'f1': 0.3404255319148936}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.535615</td>\n",
       "      <td>{'accuracy': 0.7222222222222222}</td>\n",
       "      <td>{'f1': 0.24242424242424243}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.482646</td>\n",
       "      <td>{'accuracy': 0.7666666666666667}</td>\n",
       "      <td>{'f1': 0.5116279069767442}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.499251</td>\n",
       "      <td>{'accuracy': 0.7888888888888889}</td>\n",
       "      <td>{'f1': 0.5957446808510638}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.155488</td>\n",
       "      <td>{'accuracy': 0.7666666666666667}</td>\n",
       "      <td>{'f1': 0.4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.908467</td>\n",
       "      <td>{'accuracy': 0.8222222222222222}</td>\n",
       "      <td>{'f1': 0.68}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-23)... Done. 2.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-46)... Done. 2.4s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-69)... Done. 2.3s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-92)... Done. 2.4s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-115)... Done. 2.4s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-138)... Done. 3.3s\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "095c2daf-a0b8-432c-839a-804cfa6e7d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64a12f-3d4b-4365-bcd9-20e7d24a5df3",
   "metadata": {},
   "source": [
    "## PetBERT Unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7da51c7-e622-408b-b099-4183b5b73378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PetBERT Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('SAVSNET/PetBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a958f9d6-cbd5-4ec0-87a1-b10200e5521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SAVSNET/PetBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('SAVSNET/PetBERT', num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a40c4b74-6196-4094-b1c0-c6ddd5ae9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdecc708-2dfa-4169-91a1-62936d1d335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adc86df87c24055a64ea0198bca8c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7731c0df97e04ecbb5e15ed7edb793e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2dfa3a341f45c58769ab3bb03cbd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_and_encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "91c74785-c72c-474f-9732-0693a659b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"PetBERT_UnWeighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb6f33d8-7296-4407-90e2-9eee4d519844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9850/2812224309.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='161' max='1150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 161/1150 01:37 < 10:06, 1.63 it/s, Epoch 7/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.578373</td>\n",
       "      <td>{'accuracy': 0.7111111111111111}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.567898</td>\n",
       "      <td>{'accuracy': 0.7}</td>\n",
       "      <td>{'f1': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.508651</td>\n",
       "      <td>{'accuracy': 0.7888888888888889}</td>\n",
       "      <td>{'f1': 0.5365853658536586}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.469813</td>\n",
       "      <td>{'accuracy': 0.8222222222222222}</td>\n",
       "      <td>{'f1': 0.6521739130434783}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.802042</td>\n",
       "      <td>{'accuracy': 0.8}</td>\n",
       "      <td>{'f1': 0.5263157894736842}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>{'accuracy': 0.8222222222222222}</td>\n",
       "      <td>{'f1': 0.6190476190476191}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.192707</td>\n",
       "      <td>{'accuracy': 0.8222222222222222}</td>\n",
       "      <td>{'f1': 0.6190476190476191}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted/checkpoint-23)... Done. 2.4s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted/checkpoint-46)... Done. 2.0s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted/checkpoint-69)... Done. 2.0s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted/checkpoint-92)... Done. 2.3s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted/checkpoint-115)... Done. 2.0s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted/checkpoint-138)... Done. 2.5s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted/checkpoint-161)... Done. 2.1s\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "     model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e31d2824-8543-4bef-a26e-75c52c9987cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452351b2-0f8a-40da-b187-3661b7ac3d2f",
   "metadata": {},
   "source": [
    "## PetBERT Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "899645ae-046d-4dd3-b79b-f242d16eaae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SAVSNET/PetBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('SAVSNET/PetBERT', num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6720f33c-e541-430c-9498-dc0c95068c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"PetBERT_PSOE_Binary_Classifier_Filtered_Weighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"PetBERT_Weighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "518ef9cb-adb4-498f-91a2-1d5bf1733264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9850/28312920.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='161' max='1150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 161/1150 01:39 < 10:19, 1.60 it/s, Epoch 7/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.641967</td>\n",
       "      <td>{'accuracy': 0.6555555555555556}</td>\n",
       "      <td>{'f1': 0.41509433962264153}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.567443</td>\n",
       "      <td>{'accuracy': 0.7555555555555555}</td>\n",
       "      <td>{'f1': 0.42105263157894735}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.501858</td>\n",
       "      <td>{'accuracy': 0.8111111111111111}</td>\n",
       "      <td>{'f1': 0.6046511627906976}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.476276</td>\n",
       "      <td>{'accuracy': 0.8222222222222222}</td>\n",
       "      <td>{'f1': 0.68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.763989</td>\n",
       "      <td>{'accuracy': 0.8222222222222222}</td>\n",
       "      <td>{'f1': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.811655</td>\n",
       "      <td>{'accuracy': 0.8111111111111111}</td>\n",
       "      <td>{'f1': 0.6046511627906976}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.531485</td>\n",
       "      <td>{'accuracy': 0.8111111111111111}</td>\n",
       "      <td>{'f1': 0.5641025641025641}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-23)... Done. 2.3s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-46)... Done. 2.6s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-69)... Done. 2.4s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-92)... Done. 2.8s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-115)... Done. 2.4s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-138)... Done. 2.2s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Binary_Classifier_Filtered_Weighted/checkpoint-161)... Done. 2.4s\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5966847-3c09-4265-8442-d739c1cf7b97",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa532a08-108e-4e03-9ab8-f2553b89fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "  inputs = tokenizer(text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "  outputs = model(**inputs)\n",
    "  predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "  predicted_class = torch.argmax(predictions).item()\n",
    "  confidence_score = predictions.squeeze()[predicted_class].item()\n",
    "  return predicted_class, confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d3e4aa5-2790-4434-af70-e8fd6748c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BERT_PSOE_Binary_Classifier_Filtered_Unweighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BERT_PSOE_Binary_Classifier_Filtered_Unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4d38aed-2523-4087-90b1-28aa94830e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"BERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d0b88e2-ddec-4374-aeaa-5a021b5be2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BERT_PSOE_Binary_Classifier_Filtered_Weighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BERT_PSOE_Binary_Classifier_Filtered_Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3d8bbd1-f72f-4e07-be94-44d1e22c7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"BERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1163c32-83a6-49c1-880b-14c4ac781123",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"DogBERT_PSOE_Binary_Classifier_Filtered_Unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de6c7a2a-74b2-48da-bfb3-7dbde71a0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"DogBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e2be89e-9493-45fd-8f57-5f664fa778f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DogBERT_PSOE_Binary_Classifier_Filtered_Weighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"DogBERT_PSOE_Binary_Classifier_Filtered_Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f3b7fe74-c9d6-42c0-a795-d6cecc741d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"DogBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "baae3c02-779d-47dd-a7b9-4e2fa3ec2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"PetBERT_PSOE_Binary_Classifier_Filtered_UnWeighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6acef8d-fb18-471c-8805-af74c137cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"PetBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d84c605-a475-4acd-846f-65bec93d2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"PetBERT_PSOE_Binary_Classifier_Filtered_Weighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"PetBERT_PSOE_Binary_Classifier_Filtered_Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9256a9ab-e386-4284-b420-953a0de559c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"PetBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf7c9232-699a-4f06-8b4f-4e06551f9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('infernece.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd0ead91-4113-4451-b0f1-97c1e496702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMetricDict(preds, labels):\n",
    "    \"\"\"\n",
    "    Function to create a dictionary of ML metrics from the output of a multilabel model\n",
    "\n",
    "    Args: list of predictions, list of ground truth labels\n",
    "    \"\"\"\n",
    "    metric_dict = {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"], \n",
    "                   \"precision\":precision.compute(predictions=predictions, references=labels)[\"precision\"], \n",
    "                   \"recall\":recall.compute(predictions=predictions, references=labels)[\"recall\"], \n",
    "                   \"f1\":f1.compute(predictions=predictions, references=labels)[\"f1\"]}\n",
    "\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df77f2a9-44f3-4682-862e-adc94eb18b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "predictions = list(df_test['BERT_unweighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "bert_uw_metrics = CreateMetricDict(predictions, labels)\n",
    "\n",
    "predictions = list(df_test['BERT_weighted_predicted_pseudomonas_otitis'])\n",
    "bert_w_metrics = CreateMetricDict(predictions, labels)\n",
    "\n",
    "predictions = list(df_test['DogBERT_unweighted_predicted_pseudomonas_otitis'])\n",
    "dogbert_uw_metrics = CreateMetricDict(predictions, labels)\n",
    "\n",
    "predictions = list(df_test['DogBERT_weighted_predicted_pseudomonas_otitis'])\n",
    "dogbert_w_metrics = CreateMetricDict(predictions, labels)\n",
    "\n",
    "predictions = list(df_test['PetBERT_unweighted_predicted_pseudomonas_otitis'])\n",
    "petbert_uw_metrics = CreateMetricDict(predictions, labels)\n",
    "\n",
    "predictions = list(df_test['PetBERT_weighted_predicted_pseudomonas_otitis'])\n",
    "petbert_w_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c287ab5-d81b-4b19-a6b5-a569a8293905",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = [bert_uw_metrics, bert_w_metrics, dogbert_uw_metrics, dogbert_w_metrics, petbert_uw_metrics, petbert_w_metrics]\n",
    "\n",
    "metrics_dict = {'model':['BERT (unweighted loss)', 'BERT (weighted loss)','DogBERT (unweighted loss)', 'DogBERT (weighted loss)','PetBERT (unweighted loss)', 'PetBERT (weighted loss)'], 'accuracy': [],'precision':[], 'recall':[], 'f1': []}\n",
    "\n",
    "\n",
    "for model in dicts:\n",
    "    for metric in model.keys():\n",
    "        metrics_dict[metric].append(model[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3cb3c627-8854-4cd1-b439-42cd9be8a775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['BERT (unweighted loss)', 'BERT (weighted loss)', 'DogBERT (unweighted loss)', 'DogBERT (weighted loss)', 'PetBERT (unweighted loss)', 'PetBERT (weighted loss)'], 'accuracy': [0.7191011235955056, 0.6629213483146067, 0.8539325842696629, 0.8089887640449438, 0.7640449438202247, 0.7528089887640449], 'precision': [0.0, 0.14285714285714285, 0.7307692307692307, 0.7222222222222222, 0.5714285714285714, 0.5483870967741935], 'recall': [0.0, 0.04, 0.76, 0.52, 0.64, 0.68], 'f1': [0.0, 0.0625, 0.7450980392156863, 0.6046511627906976, 0.6037735849056604, 0.6071428571428571]}\n"
     ]
    }
   ],
   "source": [
    "print(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da271546-8d8e-4f24-be28-39a1a949c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "metrics_df.to_csv('Pseudomonas_Otitis_Unbalanced_Binary_Evaluation_Metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e65841-c75b-4689-9816-b8d56c893480",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv('Pseudomonas_Otitis_Unbalanced_Binary_Evaluation_Metrics.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdef216d-07b5-4f36-b1ce-17e074447cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model  accuracy  precision  recall        f1\n",
      "0     BERT (unweighted loss)  0.719101   0.000000    0.00  0.000000\n",
      "1       BERT (weighted loss)  0.662921   0.142857    0.04  0.062500\n",
      "2  DogBERT (unweighted loss)  0.853933   0.730769    0.76  0.745098\n",
      "3    DogBERT (weighted loss)  0.808989   0.722222    0.52  0.604651\n",
      "4  PetBERT (unweighted loss)  0.764045   0.571429    0.64  0.603774\n",
      "5    PetBERT (weighted loss)  0.752809   0.548387    0.68  0.607143\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86841fbe-fdc7-442f-968c-648091654558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "model & accuracy & precision & recall & f1 \\\\\n",
      "\\midrule\n",
      "BERT (unweighted loss) & 0.72 & 0.00 & 0.00 & 0.00 \\\\\n",
      "BERT (weighted loss) & 0.66 & 0.14 & 0.04 & 0.06 \\\\\n",
      "DogBERT (unweighted loss) & 0.85 & 0.73 & 0.76 & 0.75 \\\\\n",
      "DogBERT (weighted loss) & 0.81 & 0.72 & 0.52 & 0.60 \\\\\n",
      "PetBERT (unweighted loss) & 0.76 & 0.57 & 0.64 & 0.60 \\\\\n",
      "PetBERT (weighted loss) & 0.75 & 0.55 & 0.68 & 0.61 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df.to_latex(index=False,\n",
    "                    formatters={\"name\": str.upper},\n",
    "                    float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697088e-18b1-4e49-9630-7e9c085d8a75",
   "metadata": {},
   "source": [
    "## Try scaling the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c9233ff-9e40-4b64-a177-932291e33878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.4878])\n"
     ]
    }
   ],
   "source": [
    "# iterate over each column and calculate the weight based on max value in column\n",
    "#def calculate_class_weights(train_dataset, label_cols):\n",
    "labels = list(label2id.values())\n",
    "total_samples = len(df_train)\n",
    "label_lst = []\n",
    "class_weights = []\n",
    "for label in labels:\n",
    "    class_frequency = df_train['label'].value_counts()[label]\n",
    "    weight = total_samples / (2 * class_frequency)\n",
    "    class_weights.append(weight)\n",
    "    label_lst.append(label)\n",
    "        \n",
    "# Scale weights based on minimum class weight\n",
    "min_class_weight = min(class_weights)\n",
    "if min_class_weight < 1:\n",
    "    class_weights = [x/min_class_weight for x in class_weights]\n",
    "weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d24f81-605e-4d3d-9b21-311105b4f963",
   "metadata": {},
   "source": [
    "## DogBERT Scaled Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4599a582-7901-4e15-a947-ddde21f6ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_dir = \"/opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ad118aa-88e3-4688-a09c-6fc899eaaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "15b48858-4a99-4d16-857a-7881422df3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744c63126ad34642b921ebb6c2b92ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_and_encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5011ec4a-369f-48fc-82a3-385b7c23a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"DogBERT_Weighted_Scaled\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9472a8b7-13a1-4db0-aa4a-4b87322ecb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(\n",
    "            weight=weights\n",
    "        ).to(\"cuda\")\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cff5a415-da1f-454c-9950-201d4361c85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/690 01:25 < 05:46, 1.59 it/s, Epoch 6/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.645493</td>\n",
       "      <td>{'accuracy': 0.6444444444444445}</td>\n",
       "      <td>{'f1': 0.5294117647058824}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.547928</td>\n",
       "      <td>{'accuracy': 0.7888888888888889}</td>\n",
       "      <td>{'f1': 0.6415094339622641}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.429582</td>\n",
       "      <td>{'accuracy': 0.8333333333333334}</td>\n",
       "      <td>{'f1': 0.7169811320754716}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.470682</td>\n",
       "      <td>{'accuracy': 0.8111111111111111}</td>\n",
       "      <td>{'f1': 0.711864406779661}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.608288</td>\n",
       "      <td>{'accuracy': 0.8111111111111111}</td>\n",
       "      <td>{'f1': 0.6046511627906976}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.664527</td>\n",
       "      <td>{'accuracy': 0.8222222222222222}</td>\n",
       "      <td>{'f1': 0.6666666666666666}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled/checkpoint-23)... Done. 2.3s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled/checkpoint-46)... Done. 1.9s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled/checkpoint-69)... Done. 2.3s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled/checkpoint-92)... Done. 2.2s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled/checkpoint-115)... Done. 2.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled/checkpoint-138)... Done. 2.2s\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d98925d-9a59-4b23-8fd2-dabe4c9997d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"DogBERT_PSOE_Binary_Classifier_Filtered_Weighted_Scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e36b715-21ae-4af0-9e17-e730654455a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"DogBERT_scaled_weighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT__scaled_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "15ba213a-1d77-43f2-9ba4-c3e7fe163234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('infernece.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a723d0c-9a06-4c51-ac3c-842cf0fe3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(df_test['DogBERT_scaled_weighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "dogbert_sw_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "06d279f1-34b7-4377-8102-cc2e31f7a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7865168539325843, 'precision': 0.6363636363636364, 'recall': 0.56, 'f1': 0.5957446808510638}\n"
     ]
    }
   ],
   "source": [
    "print(dogbert_sw_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9089488f-b654-47a3-a5e1-59814c681fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dogbert_weighted = df_test[['text', 'label', 'DogBERT_weighted_predicted_pseudomonas_otitis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f59c6ced-3134-48de-86b3-4c09cffd0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3e7cbf5d-c7a9-4655-be59-e84e2c6d6dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  label  \\\n",
      "0   \"Axillae and interdigital skin look great. Not...      1   \n",
      "1   \"owner reports much better, no longer nibbling...      1   \n",
      "2   \"Aged dog, few conditions of concern: 1) bilat...      1   \n",
      "3   \"Re ex R ear. O reports run out of meds on sun...      1   \n",
      "4   \"REASON: poc, report results. Doing well, stil...      1   \n",
      "..                                                ...    ...   \n",
      "84  \"Has recovered well from operation and good ap...      0   \n",
      "85  \"Ears improved - much less moist and less wax ...      0   \n",
      "86  \"SIJ Pseudomonas Otitis externa; Pododermatiti...      0   \n",
      "87  \"sudden onset smell from right ear, shaking he...      0   \n",
      "88  \"Bilateral severe OE, owner reports very letha...      0   \n",
      "\n",
      "    DogBERT_weighted_predicted_pseudomonas_otitis  \n",
      "0                                               1  \n",
      "1                                               1  \n",
      "2                                               0  \n",
      "3                                               0  \n",
      "4                                               1  \n",
      "..                                            ...  \n",
      "84                                              0  \n",
      "85                                              0  \n",
      "86                                              0  \n",
      "87                                              0  \n",
      "88                                              0  \n",
      "\n",
      "[89 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
     ]
    }
   ],
   "source": [
    "print(df_test_dogbert_weighted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
