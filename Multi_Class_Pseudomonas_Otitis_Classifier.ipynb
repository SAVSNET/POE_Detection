{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270c92f8-53b8-4793-b748-7d4e045a4632",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506c61de-1545-46a7-96d2-105c94a7feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from datasets import load_dataset, load_metric\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import accelerate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac188e5-6a23-4e02-a524-7585a3ac61f2",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8563d2-5b5a-4aa3-a06b-5f0d30b8c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/jupyterlab/notebooks/DogBERT/Classifiers/Pseudomonas_Otitis/Multi_Class Classifier/Weighted Loss\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c339a4fa-5e5b-45c2-b5fe-e2610f1ee480",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ac4c4e-7744-4540-a6df-1058fbe09c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psoe = pd.read_excel('adamwilliams-OtitisStudyPseudomonas (1).xls', sheet_name='Case Data', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ccb388-865a-4c63-ad8d-eb5cfa278b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../../savsnet_resources/pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66419bc-efb9-401e-bb48-9714ff2abdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_narratives = pd.read_pickle('narrative_pickle.pkl.gz', compression='gzip').drop_duplicates(subset='savsnet_consult_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21dce334-f041-4d5a-ab29-fa787318745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../DogBERT/Classifiers/Pseudomonas_Otitis/Multi_Class Classifier/Weighted Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "897add89-889e-48de-b663-9b6e3d46d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for just dog records\n",
    "df_psoe = df_psoe[df_psoe.species == 'dog']\n",
    "\n",
    "# Remove unclassified records\n",
    "df_psoe = df_psoe.dropna(subset=['PseudomonasOtitis'])\n",
    "\n",
    "\"\"\"\n",
    "Create Dataset\n",
    "\"\"\"\n",
    "# Join in tick labels\n",
    "df_dataset = pd.merge(df_narratives, df_psoe, on='savsnet_consult_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf64522a-db78-42ef-bba4-5a8c7d84653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           item_text  consult_record       pk  \\\n",
      "0  \"<<identifier>> otitis externa been really goo...          231003  2040703   \n",
      "1  \"HL issues and ears. been slowing up last few ...          231674  2041630   \n",
      "2  \"bilateral oe thickened ear canals cleaning is...          232326  2042546   \n",
      "3  \"left eear purulent otitis suspecrt pseudomona...          233568  2044364   \n",
      "4  \"Bilat OE again. Not purulent or ulcerated, so...          237069  2049428   \n",
      "\n",
      "        consult_record_date  savsnet_consult_id  Unnamed: 0  \\\n",
      "0 2014-06-30 17:09:38+00:00               95721           0   \n",
      "1 2014-07-26 11:24:00+00:00              129032           1   \n",
      "2 2014-08-29 16:22:44+00:00              169684           2   \n",
      "3 2014-07-16 19:29:10+00:00              117477           3   \n",
      "4 2014-07-15 17:17:57+00:00              115552           4   \n",
      "\n",
      "             searchterm__name  narrative_item_id PseudomonasOtitis  \\\n",
      "0  Pseudomonas and ear/otitis            2040703                 ?   \n",
      "1  Pseudomonas and ear/otitis            2041630                 ✓   \n",
      "2  Pseudomonas and ear/otitis            2042546                 ✓   \n",
      "3  Pseudomonas and ear/otitis            2044364                 ✓   \n",
      "4  Pseudomonas and ear/otitis            2049428                 !   \n",
      "\n",
      "  PseudomonasOtitis related_text species  \n",
      "0                            NaN     dog  \n",
      "1                            NaN     dog  \n",
      "2                            NaN     dog  \n",
      "3                            NaN     dog  \n",
      "4                            NaN     dog  \n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecfdafd1-5347-4e62-a05e-9626089356bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?' '✓' '!' '⍉']\n",
      "{'?': 0, '✓': 1, '!': 2, '⍉': 3}\n"
     ]
    }
   ],
   "source": [
    "# Extract unique labels\n",
    "unique_labels = df_dataset['PseudomonasOtitis'].unique()\n",
    "print(unique_labels)\n",
    "# Create a dictionary to map labels to numbers\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "401f2cb0-d096-4735-9479-674c1bee76b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '?', 1: '✓', 2: '!', 3: '⍉'}\n"
     ]
    }
   ],
   "source": [
    "id2label = {i:label for i, label in enumerate(unique_labels)}\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e9a001d-487b-429a-b66b-c2eb6f5293e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label dataset   \n",
    "df_dataset['PseudomonasOtitis_ID'] = df_dataset['PseudomonasOtitis'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f6a1ea2-0cd4-46b3-9aff-842ceb1b1975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           item_text  consult_record       pk  \\\n",
      "0  \"<<identifier>> otitis externa been really goo...          231003  2040703   \n",
      "1  \"HL issues and ears. been slowing up last few ...          231674  2041630   \n",
      "2  \"bilateral oe thickened ear canals cleaning is...          232326  2042546   \n",
      "3  \"left eear purulent otitis suspecrt pseudomona...          233568  2044364   \n",
      "4  \"Bilat OE again. Not purulent or ulcerated, so...          237069  2049428   \n",
      "\n",
      "        consult_record_date  savsnet_consult_id  Unnamed: 0  \\\n",
      "0 2014-06-30 17:09:38+00:00               95721           0   \n",
      "1 2014-07-26 11:24:00+00:00              129032           1   \n",
      "2 2014-08-29 16:22:44+00:00              169684           2   \n",
      "3 2014-07-16 19:29:10+00:00              117477           3   \n",
      "4 2014-07-15 17:17:57+00:00              115552           4   \n",
      "\n",
      "             searchterm__name  narrative_item_id PseudomonasOtitis  \\\n",
      "0  Pseudomonas and ear/otitis            2040703                 ?   \n",
      "1  Pseudomonas and ear/otitis            2041630                 ✓   \n",
      "2  Pseudomonas and ear/otitis            2042546                 ✓   \n",
      "3  Pseudomonas and ear/otitis            2044364                 ✓   \n",
      "4  Pseudomonas and ear/otitis            2049428                 !   \n",
      "\n",
      "  PseudomonasOtitis related_text species  PseudomonasOtitis_ID  \n",
      "0                            NaN     dog                     0  \n",
      "1                            NaN     dog                     1  \n",
      "2                            NaN     dog                     1  \n",
      "3                            NaN     dog                     1  \n",
      "4                            NaN     dog                     2  \n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742c2623-b732-46ac-a622-c43d179cbd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  \"<<identifier>> otitis externa been really goo...\n",
      "1      1  \"HL issues and ears. been slowing up last few ...\n",
      "2      1  \"bilateral oe thickened ear canals cleaning is...\n",
      "3      1  \"left eear purulent otitis suspecrt pseudomona...\n",
      "4      2  \"Bilat OE again. Not purulent or ulcerated, so...\n"
     ]
    }
   ],
   "source": [
    "df_dataset = df_dataset[[\"PseudomonasOtitis_ID\", 'item_text']].reset_index()\n",
    "# Rename columns\n",
    "df_dataset = df_dataset.rename(columns={'PseudomonasOtitis_ID':'label', 'item_text':'text'})\n",
    "df_dataset = df_dataset.drop(\"index\", axis=1)\n",
    "print(df_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d17cc0b1-ced7-412d-8b5e-201fc2769cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    638\n",
      "0    143\n",
      "2     74\n",
      "3     39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196ffcf-78a8-49a2-8e61-6031bb451dc5",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77532e1b-7a66-4b7f-8f40-7fc8677a6b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714 89 91\n"
     ]
    }
   ],
   "source": [
    "# Generate train/val/test split \n",
    "\"\"\"\n",
    "Split Each Category into 80/10/10 train/val/test sets\n",
    "\"\"\"\n",
    "# for each label in the dataframe, randomly select the number of records in the group_size. Note each index selected and remove from test set\n",
    "import random\n",
    "\n",
    "# def proportional_split_train_val_test(df):\n",
    "# get labels\n",
    "labels = df_dataset['label'].unique()\n",
    "    \n",
    "# Set up train_set, val_set and test_set\n",
    "train_set = []\n",
    "val_set = []\n",
    "test_set = []\n",
    "    \n",
    "#iterate over labels\n",
    "for label in labels:\n",
    "    # Get indexes of labels in a given group\n",
    "    indexes = df_dataset[df_dataset['label'] == label].index.to_list()\n",
    "    \n",
    "    # Get size of group\n",
    "    train_size = round(len(indexes) * 0.8)\n",
    "    val_test_size = round(len(indexes) * 0.1)\n",
    "    \n",
    "    # Randomly sample train_size indexes to make train_set. Remove these indexes \n",
    "    train_indexes = random.sample(indexes, train_size)\n",
    "    train_set += train_indexes\n",
    "    \n",
    "    # Remove train_indexes from overall indexes\n",
    "    indexes = list(set(indexes) - set(train_indexes))\n",
    "    \n",
    "    # Randomly sample val_test_size indexes to make val_set. Remove these indexes\n",
    "    val_indexes = random.sample(indexes, val_test_size)\n",
    "    val_set += val_indexes\n",
    "    \n",
    "    # Remove train_indexes from overall indexes\n",
    "    indexes = list(set(indexes) - set(val_indexes))\n",
    "    test_set += indexes\n",
    "\n",
    "print(len(train_set), len(val_set), len(test_set))\n",
    "    # return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4947052b-f792-4b31-8c48-b153e9e811b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val and test dataframes\n",
    "df_train = df_dataset.iloc[train_set]\n",
    "df_val = df_dataset.iloc[val_set]\n",
    "df_test = df_dataset.iloc[test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4adab-e07c-4b99-b8fe-971927e15ea8",
   "metadata": {},
   "source": [
    "## Calculate Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a17fc3-df1d-4c0f-8fd1-a48ddfeb9ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '?', 1: '✓', 2: '!', 3: '⍉'}\n",
      "tensor([1.5658, 1.0000, 3.0254, 5.7581])\n"
     ]
    }
   ],
   "source": [
    "# iterate over each column and calculate the weight based on max value in column\n",
    "def calculate_class_weights(train_dataset, label_cols):\n",
    "    labels = list(label_cols.values())\n",
    "    total_samples = len(train_dataset)\n",
    "    label_lst = []\n",
    "    class_weights = []\n",
    "    train_dataset_vc = train_dataset['label'].value_counts()\n",
    "    for label in labels:\n",
    "        class_frequency = train_dataset_vc[label]\n",
    "        weight = total_samples / (len(labels) * class_frequency)\n",
    "        if weight < 1:\n",
    "            weight = 1\n",
    "        class_weights.append(weight)\n",
    "        label_lst.append(label)            \n",
    "    weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    return weights\n",
    "\n",
    "\n",
    "weights = calculate_class_weights(df_train, label2id)\n",
    "print(id2label)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baf5d7cf-ab44-4756-ac3a-963e2172c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv')\n",
    "df_val.to_csv('val.csv')\n",
    "df_test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a9c860c-b9fc-46bb-a31b-38cf698b1d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ed1b5ecee349858f64a683d2ff534d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e0281d2c8047b2b661d5b68979d9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5edcd1b7e7649589bd872825f5a553b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"csv\", data_files={'train': \"train.csv\",\n",
    "                                           'eval': \"val.csv\",\n",
    "                                           'test':\"test.csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01723c-bead-46b8-b5f3-bf0ed2bc48a0",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5f88c97-ef9b-4764-911d-14f17add3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e590db6-ccc0-4e9f-a8d5-81f7472c29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa5b9a3-2831-4a96-8568-a54cf1c9a44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d7a470a66546d5b1d25094707470f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/714 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f8327ac9b846eb88cf37e01b8a18f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bee66ef97548538c860a9a2b620960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_and_encode, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ecea3-2b72-408a-9396-98682977b9ab",
   "metadata": {},
   "source": [
    "## Create Unweighted BERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a55d3c70-d2ad-4084-8a44-15f6da17e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b22784f-3ab9-4248-84d5-3cb31fd5ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup weights and biases stuff\n",
    "os.environ[\"WANDB_PROJECT\"]=\"Pseudomonas_Otitis_Classifier_MC_Post_Regex\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81f4bdab-0f0d-4fbf-9c5d-6653017a28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aa8bc63-20ad-45bc-9a1f-2a0c8a96e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "006d9ef3-4e92-4777-a7f0-ef9cd3c68c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    metrics = {\"accuracy\": accuracy.compute(predictions=predictions, references=labels), \"f1_weighted\":f1.compute(predictions=predictions, references=labels, average='weighted')}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc83e8f8-19a6-49b3-9fb3-0f096ae330fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"BERT_PSOE_Multi_Class_Classifier_Unweighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"BERT_Unweighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29a1a22f-f51d-430a-8047-1cc4457617aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/2812224309.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/900 01:01 < 06:48, 1.91 it/s, Epoch 4/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.876445</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.876661</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.899711</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.919575</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-30)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-60)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-90)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-120)... Done. 1.7s\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "     model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d130c811-d341-4e24-b7d9-d691b18ba869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28668c11-e4c0-461b-b424-bf3dff1d9cf5",
   "metadata": {},
   "source": [
    "## BERT Weighted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3db20932-36d8-4dd6-a923-805b4c5a9204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c37a82a-4f1f-43e5-b0e9-41ba1329cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(\n",
    "            weight=weights\n",
    "        ).to(\"cuda\")\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbd44084-4fc8-4d83-891f-7e1dde09e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"BERT_PSOE_Multi_Class_Classifier_Weighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"BERT_Weighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a26c55f-3dcb-432a-8ac7-660b198b7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/28312920.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/900 02:03 < 05:43, 1.92 it/s, Epoch 8/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.079669</td>\n",
       "      <td>{'accuracy': 0.7078651685393258}</td>\n",
       "      <td>{'f1': 0.5960969840331165}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.087080</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.053728</td>\n",
       "      <td>{'accuracy': 0.6629213483146067}</td>\n",
       "      <td>{'f1': 0.5861105186947884}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.076201</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6150259195872709}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.048910</td>\n",
       "      <td>{'accuracy': 0.7078651685393258}</td>\n",
       "      <td>{'f1': 0.6072980203317282}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.075109</td>\n",
       "      <td>{'accuracy': 0.6853932584269663}</td>\n",
       "      <td>{'f1': 0.5930424806829301}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.063764</td>\n",
       "      <td>{'accuracy': 0.7078651685393258}</td>\n",
       "      <td>{'f1': 0.6072980203317282}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.086668</td>\n",
       "      <td>{'accuracy': 0.7078651685393258}</td>\n",
       "      <td>{'f1': 0.6388394155055691}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-30)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-60)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-90)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-120)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-150)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-180)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-210)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./BERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-240)... Done. 1.7s\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc708ef5-f113-4afd-929a-6c99b0e86725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a502c82-b1a9-4a36-b755-cab54419d7a7",
   "metadata": {},
   "source": [
    "## DogBERT Unweighted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3954374-4663-4f26-80ec-2f6fc0004c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_dir = \"/opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=4, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37a1ee9f-f69f-46f4-a042-b19b5e02e886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"DogBERT_PSOE_Multi_Class_Classifier_Unweighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"DogBERT_Unweighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5586ae8d-1892-4676-b2e3-193fd92b2edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/2812224309.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/600 01:53 < 04:27, 1.57 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.861975</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.704413</td>\n",
       "      <td>{'accuracy': 0.6966292134831461}</td>\n",
       "      <td>{'f1': 0.6125353512191394}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.576660</td>\n",
       "      <td>{'accuracy': 0.7865168539325843}</td>\n",
       "      <td>{'f1': 0.7574522231825604}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.578270</td>\n",
       "      <td>{'accuracy': 0.7865168539325843}</td>\n",
       "      <td>{'f1': 0.7841544223566695}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677979</td>\n",
       "      <td>{'accuracy': 0.797752808988764}</td>\n",
       "      <td>{'f1': 0.7855208461950036}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.595179</td>\n",
       "      <td>{'accuracy': 0.8426966292134831}</td>\n",
       "      <td>{'f1': 0.844087747458534}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-30)... Done. 2.0s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-60)... Done. 1.9s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-90)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-120)... Done. 1.8s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-150)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Unweighted/checkpoint-180)... Done. 1.8s\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "     model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "313f65c4-4a77-4a2c-ac9a-dc5870d323ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cc224-2174-4128-82ea-d3ca54b273fe",
   "metadata": {},
   "source": [
    "## DogBERT Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d6d9a22-64cc-47f8-9211-7374c8c75837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model_dir = \"/opt/jupyterlab/notebooks/DogBERT/Domain Adaptation/DogBERT v0.0.2\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=4, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c8b8d1d-86df-43e0-a82d-9f360362b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"DogBERT_PSOE_Multi_Class_Classifier_Weighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"DogBERT_Weighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e795c5f-bcd6-4538-91cf-797b27eb0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/28312920.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/900 01:49 < 06:02, 1.90 it/s, Epoch 7/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.012914</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.761601</td>\n",
       "      <td>{'accuracy': 0.7078651685393258}</td>\n",
       "      <td>{'f1': 0.6527719471539696}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.637763</td>\n",
       "      <td>{'accuracy': 0.7865168539325843}</td>\n",
       "      <td>{'f1': 0.7907312254368946}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.521367</td>\n",
       "      <td>{'accuracy': 0.8314606741573034}</td>\n",
       "      <td>{'f1': 0.8371390600459104}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.587775</td>\n",
       "      <td>{'accuracy': 0.8426966292134831}</td>\n",
       "      <td>{'f1': 0.8435283748069018}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.621990</td>\n",
       "      <td>{'accuracy': 0.8426966292134831}</td>\n",
       "      <td>{'f1': 0.8338588043141562}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.779723</td>\n",
       "      <td>{'accuracy': 0.8314606741573034}</td>\n",
       "      <td>{'f1': 0.8194980155402761}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-30)... Done. 1.8s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-60)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-90)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-120)... Done. 1.9s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-150)... Done. 2.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-180)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./DogBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-210)... Done. 1.7s\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0e87c17-d240-4cb9-8e96-59052ff03036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb0871-3c9c-4d41-9001-1e9fc33783d5",
   "metadata": {},
   "source": [
    "## PetBERT Unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "989efa31-8654-4f46-ad26-3fd8f2e6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PetBERT Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('SAVSNET/PetBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02908424-dc98-413e-bf6f-663513ef035d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SAVSNET/PetBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('SAVSNET/PetBERT', num_labels=4, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa6718b7-a24d-4e69-9274-558fb686e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f560e8bc-f896-4279-8fe3-ee32408fedc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db49476d10a499ebdd9d6e85db04877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/714 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f17a9a346646eaa689d5e9dda885f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b70ed218c54af083db703e6be49785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_and_encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f8cbd07-0644-49a3-b9fc-ca9a55c04654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"PetBERT_PSOE_Multi_Class_Classifier_UnWeighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"PetBERT_UnWeighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99a0524d-5a6d-44be-bc76-7663db4ecea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/2812224309.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 180/1500 01:33 < 11:31, 1.91 it/s, Epoch 6/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.854833</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702463</td>\n",
       "      <td>{'accuracy': 0.7078651685393258}</td>\n",
       "      <td>{'f1': 0.6308552665332717}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.665367</td>\n",
       "      <td>{'accuracy': 0.7640449438202247}</td>\n",
       "      <td>{'f1': 0.7303769628734872}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.855561</td>\n",
       "      <td>{'accuracy': 0.7303370786516854}</td>\n",
       "      <td>{'f1': 0.7111063094209161}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.867961</td>\n",
       "      <td>{'accuracy': 0.6966292134831461}</td>\n",
       "      <td>{'f1': 0.7044935515749438}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.006251</td>\n",
       "      <td>{'accuracy': 0.7303370786516854}</td>\n",
       "      <td>{'f1': 0.7298703489889937}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_UnWeighted/checkpoint-30)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_UnWeighted/checkpoint-60)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_UnWeighted/checkpoint-90)... Done. 1.7s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_UnWeighted/checkpoint-120)... Done. 1.8s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_UnWeighted/checkpoint-150)... Done. 1.8s\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_UnWeighted/checkpoint-180)... Done. 1.7s\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "     model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0091970b-fdd7-4ee5-b698-3358217657b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd9ba4-0c19-4ea3-8c95-d1e98c177e71",
   "metadata": {},
   "source": [
    "## PetBERT Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d6a734c-4ac5-43bb-86dc-9d17e20c1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SAVSNET/PetBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('SAVSNET/PetBERT', num_labels=4, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4845d381-2326-45a7-9f37-6cc32feafb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"PetBERT_PSOE_Multi_Class_Classifier_Weighted\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy = \"epoch\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = True,\n",
    "    run_name=\"PetBERT_Weighted\",\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9795ef6-123c-462d-ba52-83fc13f661bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/28312920.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 180/1500 01:33 < 11:31, 1.91 it/s, Epoch 6/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.000918</td>\n",
       "      <td>{'accuracy': 0.7191011235955056}</td>\n",
       "      <td>{'f1': 0.6016009400014688}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.873487</td>\n",
       "      <td>{'accuracy': 0.6966292134831461}</td>\n",
       "      <td>{'f1': 0.630837327466541}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.720505</td>\n",
       "      <td>{'accuracy': 0.6853932584269663}</td>\n",
       "      <td>{'f1': 0.6917814800464935}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.782366</td>\n",
       "      <td>{'accuracy': 0.6853932584269663}</td>\n",
       "      <td>{'f1': 0.6836908409942118}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.897063</td>\n",
       "      <td>{'accuracy': 0.7303370786516854}</td>\n",
       "      <td>{'f1': 0.7102290209917681}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>{'accuracy': 0.7078651685393258}</td>\n",
       "      <td>{'f1': 0.7085753198112749}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-30)... Done. 1.9s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-60)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-90)... Done. 1.8s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-120)... Done. 1.9s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-150)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./PetBERT_PSOE_Multi_Class_Classifier_Weighted/checkpoint-180)... Done. 1.7s\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61bdc6fb-cdba-4b63-af8c-f325eefe0d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22efee1-26ff-4011-9dd9-7c6e44c5cfad",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "795c3e76-0d47-4559-87be-87d344e7640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "  inputs = tokenizer(text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "  outputs = model(**inputs)\n",
    "  predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "  predicted_class = torch.argmax(predictions).item()\n",
    "  confidence_score = predictions.squeeze()[predicted_class].item()\n",
    "  return predicted_class, confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abae335b-dd14-4333-8234-2d006c5fffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BERT_PSOE_Multi_Class_Classifier_Unweighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BERT_PSOE_Multi_Class_Classifier_Unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78582230-1546-4223-b1f2-2c726c8baf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/2392519462.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"BERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n",
      "/tmp/ipykernel_18505/2392519462.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"BERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"BERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74058ad1-ab11-47f6-807a-f6a0540e9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BERT_PSOE_Multi_Class_Classifier_Weighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BERT_PSOE_Multi_Class_Classifier_Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cdcf0c1-d75f-45b6-9be3-e65e55e0cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/711888235.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"BERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n",
      "/tmp/ipykernel_18505/711888235.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"BERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"BERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"BERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19b57ce4-2414-46bb-8b75-daadcefcf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DogBERT_PSOE_Multi_Class_Classifier_Unweighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"DogBERT_PSOE_Multi_Class_Classifier_Unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8ff54fb-0065-4dd6-a431-52ff965e6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/2310829365.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"DogBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n",
      "/tmp/ipykernel_18505/2310829365.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"DogBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"DogBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81a108df-ef44-4fa7-876e-6623f5ae1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DogBERT_PSOE_Multi_Class_Classifier_Weighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"DogBERT_PSOE_Multi_Class_Classifier_Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "999a4abe-a1a1-4f84-bbf2-19f9685f23bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/2141520009.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"DogBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n",
      "/tmp/ipykernel_18505/2141520009.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"DogBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"DogBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"DogBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "000ba3ca-e4b5-4652-983a-7c803fde2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"PetBERT_PSOE_Multi_Class_Classifier_UnWeighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"PetBERT_PSOE_Multi_Class_Classifier_UnWeighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "605a933c-58d0-43bf-8c35-f7939f06baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/942047724.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"PetBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n",
      "/tmp/ipykernel_18505/942047724.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"PetBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"PetBERT_unweighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_unweighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5052a1f4-de64-4d86-8deb-bf5f21957dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"PetBERT_PSOE_Multi_Class_Classifier_Weighted\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"PetBERT_PSOE_Multi_Class_Classifier_Weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c494894-dbb9-4e06-8c8b-1818639c9c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18505/1821737227.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"PetBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n",
      "/tmp/ipykernel_18505/1821737227.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"PetBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called 'df' and the text column is 'text'\n",
    "df_test[\"PetBERT_weighted_predicted_pseudomonas_otitis\"], df_test[\"PetBERT_weighted_confidence_score\"] = zip(*df_test[\"text\"].apply(predict_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "59d42ca5-e133-4fe6-a283-b9c32434bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                               text  \\\n",
      "0        0  \"<<identifier>> otitis externa been really goo...   \n",
      "357      0  \".  Next appointment in 3 weeks. Continued imp...   \n",
      "631      0  \"ES: recheck leg and check ears. OR doing well...   \n",
      "520      0  \"Aged dog, few conditions of concern: 1) bilat...   \n",
      "138      0  \"O feels ear no better. Purulent discharge wit...   \n",
      "\n",
      "     BERT_unweighted_predicted_pseudomonas_otitis  \\\n",
      "0                                               1   \n",
      "357                                             1   \n",
      "631                                             1   \n",
      "520                                             1   \n",
      "138                                             1   \n",
      "\n",
      "     BERT_unweighted_confidence_score  \\\n",
      "0                            0.695481   \n",
      "357                          0.706644   \n",
      "631                          0.705835   \n",
      "520                          0.690102   \n",
      "138                          0.714850   \n",
      "\n",
      "     BERT_weighted_predicted_pseudomonas_otitis  \\\n",
      "0                                             1   \n",
      "357                                           1   \n",
      "631                                           1   \n",
      "520                                           3   \n",
      "138                                           1   \n",
      "\n",
      "     BERT_weighted_confidence_score  \\\n",
      "0                          0.544422   \n",
      "357                        0.640200   \n",
      "631                        0.630411   \n",
      "520                        0.503940   \n",
      "138                        0.624558   \n",
      "\n",
      "     DogBERT_unweighted_predicted_pseudomonas_otitis  \\\n",
      "0                                                  1   \n",
      "357                                                1   \n",
      "631                                                0   \n",
      "520                                                1   \n",
      "138                                                1   \n",
      "\n",
      "     DogBERT_unweighted_confidence_score  \\\n",
      "0                               0.964930   \n",
      "357                             0.367983   \n",
      "631                             0.585867   \n",
      "520                             0.717484   \n",
      "138                             0.626278   \n",
      "\n",
      "     DogBERT_weighted_predicted_pseudomonas_otitis  \\\n",
      "0                                                1   \n",
      "357                                              0   \n",
      "631                                              0   \n",
      "520                                              1   \n",
      "138                                              1   \n",
      "\n",
      "     DogBERT_weighted_confidence_score  \\\n",
      "0                             0.960905   \n",
      "357                           0.478261   \n",
      "631                           0.747148   \n",
      "520                           0.624650   \n",
      "138                           0.659977   \n",
      "\n",
      "     PetBERT_unweighted_predicted_pseudomonas_otitis  \\\n",
      "0                                                  1   \n",
      "357                                                0   \n",
      "631                                                1   \n",
      "520                                                1   \n",
      "138                                                1   \n",
      "\n",
      "     PetBERT_unweighted_confidence_score  \\\n",
      "0                               0.968905   \n",
      "357                             0.367861   \n",
      "631                             0.482869   \n",
      "520                             0.762184   \n",
      "138                             0.884174   \n",
      "\n",
      "     PetBERT_weighted_predicted_pseudomonas_otitis  \\\n",
      "0                                                1   \n",
      "357                                              2   \n",
      "631                                              0   \n",
      "520                                              1   \n",
      "138                                              1   \n",
      "\n",
      "     PetBERT_weighted_confidence_score  \n",
      "0                             0.880724  \n",
      "357                           0.674824  \n",
      "631                           0.467817  \n",
      "520                           0.595307  \n",
      "138                           0.714790  \n"
     ]
    }
   ],
   "source": [
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0bc0325b-8795-43f3-b945-ba6cb9c59505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMetricDict(preds, labels):\n",
    "    \"\"\"\n",
    "    Function to create a dictionary of ML metrics from the output of a multilabel model\n",
    "\n",
    "    Args: list of predictions, list of ground truth labels\n",
    "    \"\"\"\n",
    "    metric_dict = {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"], \n",
    "                   \"precision_raw\":precision.compute(predictions=predictions, references=labels, average=None)[\"precision\"], \n",
    "                   \"recall_raw\":recall.compute(predictions=predictions, references=labels, average=None)[\"recall\"], \n",
    "                   \"f1_raw\":f1.compute(predictions=predictions, references=labels, average=None)[\"f1\"], \n",
    "                   \"precision_macro\":precision.compute(predictions=predictions, references=labels, average='macro')[\"precision\"], \n",
    "                   \"recall_macro\":recall.compute(predictions=predictions, references=labels, average='macro')[\"recall\"], \n",
    "                   \"f1_macro\":f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"], \n",
    "                   \"precision_weighted\":precision.compute(predictions=predictions, references=labels, average='weighted')[\"precision\"],\n",
    "                   \"recall_weighted\":recall.compute(predictions=predictions, references=labels, average='weighted')[\"recall\"],\n",
    "                   \"f1_weighted\":f1.compute(predictions=predictions, references=labels, average='weighted')[\"f1\"]\n",
    "                  }\n",
    "\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e6c5c58-d248-4338-98b0-2ad63f36efac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "predictions = list(df_test['BERT_unweighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "bert_uw_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ee25832-df89-4a88-bfb6-2e69ff6155a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7032967032967034, 'precision_raw': array([0.       , 0.7032967, 0.       , 0.       ]), 'recall_raw': array([0., 1., 0., 0.]), 'f1_raw': array([0.        , 0.82580645, 0.        , 0.        ]), 'precision_macro': 0.17582417582417584, 'recall_macro': 0.25, 'f1_macro': 0.2064516129032258, 'precision_weighted': 0.49462625286801115, 'recall_weighted': 0.7032967032967034, 'f1_weighted': 0.5807869549805034}\n"
     ]
    }
   ],
   "source": [
    "print(bert_uw_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3cc7a77c-1306-4090-b6f7-6bdaf17ceba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = list(df_test['BERT_weighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "bert_w_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60f54d95-d3cc-4950-8ab1-01c986573e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7032967032967034, 'precision_raw': array([0.        , 0.71111111, 0.        , 0.        ]), 'recall_raw': array([0., 1., 0., 0.]), 'f1_raw': array([0.        , 0.83116883, 0.        , 0.        ]), 'precision_macro': 0.17777777777777778, 'recall_macro': 0.25, 'f1_macro': 0.2077922077922078, 'precision_weighted': 0.5001221001221001, 'recall_weighted': 0.7032967032967034, 'f1_weighted': 0.5845582988440131}\n"
     ]
    }
   ],
   "source": [
    "print(bert_w_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5b949ed3-59a3-4e5c-a475-cdabdbdc7d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = list(df_test['DogBERT_unweighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "dogbert_uw_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0faa6411-dffb-445a-9c73-cc4732712658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7692307692307693, 'precision_raw': array([0.4       , 0.86956522, 0.        , 1.        ]), 'recall_raw': array([0.53333333, 0.9375    , 0.        , 0.5       ]), 'f1_raw': array([0.45714286, 0.90225564, 0.        , 0.66666667]), 'precision_macro': 0.567391304347826, 'recall_macro': 0.4927083333333333, 'f1_macro': 0.506516290726817, 'precision_weighted': 0.7214524605828952, 'recall_weighted': 0.7692307692307693, 'f1_weighted': 0.7392106640226942}\n"
     ]
    }
   ],
   "source": [
    "print(dogbert_uw_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3251e558-bd53-451c-9bd9-d0a13c4270d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(df_test['DogBERT_weighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "dogbert_w_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1015d130-0693-4e0e-9233-eef908ae2f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8131868131868132, 'precision_raw': array([0.58823529, 0.890625  , 0.85714286, 0.33333333]), 'recall_raw': array([0.66666667, 0.890625  , 0.75      , 0.25      ]), 'f1_raw': array([0.625     , 0.890625  , 0.8       , 0.28571429]), 'precision_macro': 0.6673341211484595, 'recall_macro': 0.6393229166666666, 'f1_macro': 0.6503348214285714, 'precision_weighted': 0.8133407209037462, 'recall_weighted': 0.8131868131868132, 'f1_weighted': 0.8122841444270016}\n"
     ]
    }
   ],
   "source": [
    "print(dogbert_w_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7a8ff9cf-6911-4aa7-9d04-6a7b4df075e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = list(df_test['PetBERT_unweighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "petbert_uw_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c1ba385-ca68-4b7e-8c83-7ccf781127b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7252747252747253, 'precision_raw': array([0.27272727, 0.7875    , 0.        , 0.        ]), 'recall_raw': array([0.2     , 0.984375, 0.      , 0.      ]), 'f1_raw': array([0.23076923, 0.875     , 0.        , 0.        ]), 'precision_macro': 0.26505681818181814, 'recall_macro': 0.29609375, 'f1_macro': 0.2764423076923077, 'precision_weighted': 0.5988011988011989, 'recall_weighted': 0.7252747252747253, 'f1_weighted': 0.6534234995773457}\n"
     ]
    }
   ],
   "source": [
    "print(petbert_uw_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "157c29b9-740c-484e-a3e4-14404cb546a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(df_test['PetBERT_weighted_predicted_pseudomonas_otitis'])\n",
    "labels = list(df_test['label'])\n",
    "\n",
    "petbert_w_metrics = CreateMetricDict(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "316f18e9-caec-41bf-bdc4-370f6be13700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7912087912087912, 'precision_raw': array([0.5       , 0.86956522, 0.8       , 0.4       ]), 'recall_raw': array([0.4   , 0.9375, 0.5   , 0.5   ]), 'f1_raw': array([0.44444444, 0.90225564, 0.61538462, 0.44444444]), 'precision_macro': 0.6423913043478261, 'recall_macro': 0.584375, 'f1_macro': 0.6016322858428121, 'precision_weighted': 0.7818920210224557, 'recall_weighted': 0.7912087912087912, 'f1_weighted': 0.7814492557118351}\n"
     ]
    }
   ],
   "source": [
    "print(petbert_w_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "823a954b-3f79-413e-a3ce-94b2798c88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = [bert_uw_metrics, bert_w_metrics, dogbert_uw_metrics, dogbert_w_metrics, petbert_uw_metrics, petbert_w_metrics]\n",
    "\n",
    "metrics_dict = {'model':['BERT (unweighted loss)', 'BERT (weighted loss)','DogBERT (unweighted loss)', 'DogBERT (weighted loss)','PetBERT (unweighted loss)', 'PetBERT (weighted loss)'], 'accuracy': [],\n",
    "                'precision_raw':[], 'recall_raw':[], 'f1_raw': [], 'precision_macro':[], 'recall_macro':[], 'f1_macro': [], 'precision_weighted':[], 'recall_weighted':[], 'f1_weighted': []}\n",
    "\n",
    "\n",
    "for model in dicts:\n",
    "    for metric in model.keys():\n",
    "        metrics_dict[metric].append(model[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2d61298f-3068-4783-8c5b-8422a5611252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ['BERT (unweighted loss)', 'BERT (weighted loss)', 'DogBERT (unweighted loss)', 'DogBERT (weighted loss)', 'PetBERT (unweighted loss)', 'PetBERT (weighted loss)'], 'accuracy': [0.7032967032967034, 0.7032967032967034, 0.7692307692307693, 0.8131868131868132, 0.7252747252747253, 0.7912087912087912], 'precision_raw': [array([0.       , 0.7032967, 0.       , 0.       ]), array([0.        , 0.71111111, 0.        , 0.        ]), array([0.4       , 0.86956522, 0.        , 1.        ]), array([0.58823529, 0.890625  , 0.85714286, 0.33333333]), array([0.27272727, 0.7875    , 0.        , 0.        ]), array([0.5       , 0.86956522, 0.8       , 0.4       ])], 'recall_raw': [array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0.53333333, 0.9375    , 0.        , 0.5       ]), array([0.66666667, 0.890625  , 0.75      , 0.25      ]), array([0.2     , 0.984375, 0.      , 0.      ]), array([0.4   , 0.9375, 0.5   , 0.5   ])], 'f1_raw': [array([0.        , 0.82580645, 0.        , 0.        ]), array([0.        , 0.83116883, 0.        , 0.        ]), array([0.45714286, 0.90225564, 0.        , 0.66666667]), array([0.625     , 0.890625  , 0.8       , 0.28571429]), array([0.23076923, 0.875     , 0.        , 0.        ]), array([0.44444444, 0.90225564, 0.61538462, 0.44444444])], 'precision_macro': [0.17582417582417584, 0.17777777777777778, 0.567391304347826, 0.6673341211484595, 0.26505681818181814, 0.6423913043478261], 'recall_macro': [0.25, 0.25, 0.4927083333333333, 0.6393229166666666, 0.29609375, 0.584375], 'f1_macro': [0.2064516129032258, 0.2077922077922078, 0.506516290726817, 0.6503348214285714, 0.2764423076923077, 0.6016322858428121], 'precision_weighted': [0.49462625286801115, 0.5001221001221001, 0.7214524605828952, 0.8133407209037462, 0.5988011988011989, 0.7818920210224557], 'recall_weighted': [0.7032967032967034, 0.7032967032967034, 0.7692307692307693, 0.8131868131868132, 0.7252747252747253, 0.7912087912087912], 'f1_weighted': [0.5807869549805034, 0.5845582988440131, 0.7392106640226942, 0.8122841444270016, 0.6534234995773457, 0.7814492557118351]}\n"
     ]
    }
   ],
   "source": [
    "print(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3400c0fa-58f5-487a-a257-11370e7c81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "metrics_df.to_csv('Pseudomonas_Otitis_Unbalanced_Evaluation_Metrics_(New).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "282b5aa4-d9dd-4b9f-866e-0819f035a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669ace2-11ff-41cf-9a76-41f8498eb30c",
   "metadata": {},
   "source": [
    "## Create Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9597d060-9dd9-49f2-8518-26404d1fe9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv('Pseudomonas_Otitis_Unbalanced_Evaluation_Metrics_(New).csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e2d9ef4a-2e64-4ff4-b86a-1ea5461d279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model  accuracy  \\\n",
      "0     BERT (unweighted loss)  0.703297   \n",
      "1       BERT (weighted loss)  0.703297   \n",
      "2  DogBERT (unweighted loss)  0.769231   \n",
      "3    DogBERT (weighted loss)  0.813187   \n",
      "4  PetBERT (unweighted loss)  0.725275   \n",
      "5    PetBERT (weighted loss)  0.791209   \n",
      "\n",
      "                                   precision_raw  \\\n",
      "0      [0.        0.7032967 0.        0.       ]   \n",
      "1  [0.         0.71111111 0.         0.        ]   \n",
      "2  [0.4        0.86956522 0.         1.        ]   \n",
      "3  [0.58823529 0.890625   0.85714286 0.33333333]   \n",
      "4  [0.27272727 0.7875     0.         0.        ]   \n",
      "5  [0.5        0.86956522 0.8        0.4       ]   \n",
      "\n",
      "                                      recall_raw  \\\n",
      "0                                  [0. 1. 0. 0.]   \n",
      "1                                  [0. 1. 0. 0.]   \n",
      "2  [0.53333333 0.9375     0.         0.5       ]   \n",
      "3  [0.66666667 0.890625   0.75       0.25      ]   \n",
      "4          [0.2      0.984375 0.       0.      ]   \n",
      "5                  [0.4    0.9375 0.5    0.5   ]   \n",
      "\n",
      "                                          f1_raw  precision_macro  \\\n",
      "0  [0.         0.82580645 0.         0.        ]         0.175824   \n",
      "1  [0.         0.83116883 0.         0.        ]         0.177778   \n",
      "2  [0.45714286 0.90225564 0.         0.66666667]         0.567391   \n",
      "3  [0.625      0.890625   0.8        0.28571429]         0.667334   \n",
      "4  [0.23076923 0.875      0.         0.        ]         0.265057   \n",
      "5  [0.44444444 0.90225564 0.61538462 0.44444444]         0.642391   \n",
      "\n",
      "   recall_macro  f1_macro  precision_weighted  recall_weighted  f1_weighted  \n",
      "0      0.250000  0.206452            0.494626         0.703297     0.580787  \n",
      "1      0.250000  0.207792            0.500122         0.703297     0.584558  \n",
      "2      0.492708  0.506516            0.721452         0.769231     0.739211  \n",
      "3      0.639323  0.650335            0.813341         0.813187     0.812284  \n",
      "4      0.296094  0.276442            0.598801         0.725275     0.653423  \n",
      "5      0.584375  0.601632            0.781892         0.791209     0.781449  \n"
     ]
    }
   ],
   "source": [
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "22d886d3-1394-4412-8061-59cf620143ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_weighted = metrics_df[['model', 'accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e197fbc-319c-4418-839c-b1eb2be3fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model  accuracy  precision_weighted  recall_weighted  \\\n",
      "0     BERT (unweighted loss)  0.703297            0.494626         0.703297   \n",
      "1       BERT (weighted loss)  0.703297            0.500122         0.703297   \n",
      "2  DogBERT (unweighted loss)  0.769231            0.721452         0.769231   \n",
      "3    DogBERT (weighted loss)  0.813187            0.813341         0.813187   \n",
      "4  PetBERT (unweighted loss)  0.725275            0.598801         0.725275   \n",
      "5    PetBERT (weighted loss)  0.791209            0.781892         0.791209   \n",
      "\n",
      "   f1_weighted  \n",
      "0     0.580787  \n",
      "1     0.584558  \n",
      "2     0.739211  \n",
      "3     0.812284  \n",
      "4     0.653423  \n",
      "5     0.781449  \n"
     ]
    }
   ],
   "source": [
    "print(metrics_df_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6d88a1d0-94db-4d65-9507-6c4aa5e58954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "model & accuracy & precision_weighted & recall_weighted & f1_weighted \\\\\n",
      "\\midrule\n",
      "BERT (unweighted loss) & 0.70 & 0.49 & 0.70 & 0.58 \\\\\n",
      "BERT (weighted loss) & 0.70 & 0.50 & 0.70 & 0.58 \\\\\n",
      "DogBERT (unweighted loss) & 0.77 & 0.72 & 0.77 & 0.74 \\\\\n",
      "DogBERT (weighted loss) & 0.81 & 0.81 & 0.81 & 0.81 \\\\\n",
      "PetBERT (unweighted loss) & 0.73 & 0.60 & 0.73 & 0.65 \\\\\n",
      "PetBERT (weighted loss) & 0.79 & 0.78 & 0.79 & 0.78 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df_weighted.to_latex(index=False,\n",
    "                  formatters={\"name\": str.upper},\n",
    "                  float_format=\"{:.2f}\".format,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
